{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgFRQ0t8tWhM"
      },
      "source": [
        "# Übungsblatt 8 - Programmieraufgaben (15 Punkte)\n",
        "Einführung in Deep Learning für Visual Computing\n",
        "\n",
        "**Deadline : 18.06.2025 - 14:00 via VIPS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsQeNDyQtWhU"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPG2OT-PtWhU"
      },
      "outputs": [],
      "source": [
        "from typing import Type, Tuple, List\n",
        "\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from visualize import (\n",
        "    show_image_grid,\n",
        "    show_loss_curve,\n",
        "    show_distribution_samples\n",
        ")\n",
        "\n",
        "from training import (\n",
        "    train_multiclass,\n",
        "    evaluate\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5YpQ4d6tWhW"
      },
      "source": [
        "# Transfer Learning (8 Punkte)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6CrxC5RtWhW"
      },
      "source": [
        "Das Packet `Torchvision` stellt nicht nur Datensätze und Werkzeuge für das Training von Computer Vision bereit sondern auch Implementierung populärer Neuronale Netzwerke für Computer Vision. In dieser Aufgabe verwenden wir die Torchvision Implementierung von ResNet18, der kleinsten ResNet-Konfiguration, die von den Ursprünglichen Autoren untersucht wurde. Wir erhalten eine Instanz des Modells mit der Funktion\n",
        "\n",
        "`python\n",
        "resnet18 = torchvision.models.resnet18().\n",
        "`\n",
        "\n",
        "Die Funktion gibt die Instanz eines Netzwerks zurück, die aus den uns geläufigen Klassen und Funktionen in `torch.nn` aufgebaut ist. Wir können das Netzwerk verwenden wie wir es gewohnt sind. Torchvision stellt aber nicht nur die Implementierung des Netzwerks bereit, sondern auch die Netzwerkgewichte des auf ImageNet trainierten Netzwerks. Um die Gewichte zu laden, wird der Funktion ``resnet18` die gewünschten Gewichte übergeben mit\n",
        "\n",
        "`python\n",
        "resnet18 = torchvision.models.resnet18(torchvision.models.ResNet18_Weights.IMAGENET1K_V1).\n",
        "`\n",
        "\n",
        "Nach dem Erzeugen des Modells können wir auf die einzelnen Schichten des ResNet18 Modells wie folgt zugreifen:\n",
        "\n",
        "`python\n",
        "resnet18.<layer_name>\n",
        "`\n",
        "\n",
        "Die Layer des Netzwerks sind - in Reihenfolge in der Sie in der forward Methode aufgerufen werden:\n",
        "* `resnet18.conv1`\n",
        "* `resnet18.bn1`\n",
        "* `resnet18.relu`\n",
        "* `resnet18.maxpool`\n",
        "* `resnet18.layer1` (Vereint mehrere ResNet Blöcke)\n",
        "* `resnet18.layer2` (Vereint mehrere ResNet Blöcke)\n",
        "* `resnet18.layer3` (Vereint mehrere ResNet Blöcke)\n",
        "* `resnet18.layer4` (Vereint mehrere ResNet Blöcke)\n",
        "* `resnet18.avgpool`\n",
        "\n",
        "Mit Hilfe von `nn.Sequential(resnet18.conv1,resnet18.bn1,...)` können wir eine beliebige Anzahl dieser vortrainierten Layers wieder zusammenfassen und als Basis für ein neues Netzwerk verwenden. Diese vortrainierten Layer können z.B. in Kombination mit anschließenden (noch untrainierten) Linear Layers dann verwendet werden um auf neue Probleme trainiert und angewandt zu werden. Mit Hilfe von `self.layerX.requires_grad_(train_features)` kann angegeben werden, ob ein layer beim Training mitberücksichtigt oder als statisch betrachtet werden soll. In der folgenden Aufgabe werden wir verschiedene Konfiguationsmöglichkeiten für solche Transfer Learning Verfahren betrachten."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDeyG_vJtWhX"
      },
      "source": [
        "**Aufgabe :**\n",
        "1. (1 Bonus-Punkt) Vervollständigen Sie die Klasse `ResNetBlock` sodass diese einen Block aus zwei Conv.-Layers mit einer Skip-Connections implementiert, ähnlich zu Folie 25ff in Vorlesung 7. Verwenden Sie die ReLU-Funktion als Aktivierungsfunktion.\n",
        "\n",
        "2. (3 Punkte) Vervollständigen Sie die Klasse `PretrainedClassifier`, sodass diese das auf ImageNet vortrainierte ResNet18 verwendet um Feature aus den Eingabebildern zu extrahieren. Die Features sollen anschließend durch das Modul `classifier` auf 10 Klassen abgebildet werden. Wählen Sie die Schichten des Resnet aufbauend auf dem Wissen über hierarchischen CNN-Architekturen aus der Vorlesung. Geben Sie eine kurze Begründung Ihrer Auswahl.\n",
        "\n",
        "2. (4 Punkte) Trainieren Sie drei unterschiedliche Konfigurationen des Netzwerks `PretrainedClassifier`, wobei jede Konfiguration jeweils nur eine Epoche auf dem CIFAR10-Datensatz durchläuft. Die Konfigurationen sind gegeben als:\n",
        "    * In der ersten Konfiguration sollen die Gewichte des Modells zufällig initialisiert werden, und es sollen alle Parameter des Netzwerks trainiert werden.\n",
        "    * In der zweiten Konfiguration sollen die Gewichte des ResNet18 auf ImageNet vortrainiert sein, und es sollen nur die Parameter der neu hinzugefügten Layer trainiert werden.\n",
        "    * In der dritten Konfiguration sollen die Gewichte des ResNet18 auf ImageNet vortrainiert sein, und es sollen alle Parameter des Netzwerks trainiert werden.\n",
        "\n",
        "Bestimmen Sie anschließend die Genauigkeit, die auf den Testdaten des Datensatzes erreicht wird. Vergleichen Sie die Laufzeit und die Genauigkeit der drei Konfigurationen untereinander.\n",
        "\n",
        "**Hinweis :** Sie die Ihnen bereits bekannten Funktionen `train_multiclass` und `evaluate` verwenden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLVJow_DtWhZ"
      },
      "outputs": [],
      "source": [
        "class PretrainedClassifier(nn.Module):\n",
        "    def __init__(self, pretrained : bool, train_features : bool) -> None:\n",
        "        super().__init__()\n",
        "        self.train_features = train_features\n",
        "        resnet18 = torchvision.models.resnet18(torchvision.models.ResNet18_Weights.IMAGENET1K_V1 if pretrained else None)\n",
        "        # Beginn Iher Lösung\n",
        "        # Ende Ihrer Lösung\n",
        "\n",
        "    def forward(self, x : torch.Tensor) -> torch.Tensor:\n",
        "        self.features.train(self.train_features)\n",
        "        f = self.features(x)\n",
        "        #print(f.shape)\n",
        "        return self.classifer(f)\n",
        "\n",
        "class ResNetBlock(nn.Module):\n",
        "    def __init__(self, num_channels : int, kernel_size : int):\n",
        "        super().__init__()\n",
        "        # Beginn Ihrer Lösung\n",
        "        # Ende Ihrer Lösung\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Beginn Ihrer Lösung\n",
        "        pass # Ersetzen Sie `pass` durch Ihre Lösung\n",
        "        # Ende Ihrer Lösung"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnVRItyStWha"
      },
      "outputs": [],
      "source": [
        "transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
        "])\n",
        "cifar10_train = torchvision.datasets.CIFAR10(\"./\", True, transform=transforms, download=True)\n",
        "dataloader = torch.utils.data.DataLoader(cifar10_train, 128, True)\n",
        "cifar10_test = torchvision.datasets.CIFAR10(\"./\", False, transform=transforms, download=True)\n",
        "dataloader_test = torch.utils.data.DataLoader(cifar10_test, 128, True)\n",
        "\n",
        "# Training und Evaluation der Modelle\n",
        "# Beginn Ihrer Lösung\n",
        "# Ende Ihrer Lösung"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8rhT0R1tWhc"
      },
      "source": [
        "# Generative Adversarial Networks (7 Punkte)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_KbQHzUtWhd"
      },
      "source": [
        "**Aufgabe :**\n",
        "\n",
        "1. (5 Punkte) Implementieren Sie den Algorithmus zum Trainieren eines GANs, wie er in Vorlesung 9, Folie 19 beschrieben ist, indem Sie die Funktion `train_gan` vervollständigen. Setzen Sie bei der Implementierung des Algorithmus $k=1$. Das Training soll für `num_epochs` durchgeführt werden. Am Ende jeder Epoche sollen 25 Stichproben (Bilder) mit dem Generator erzeugt und der Liste `img_list` hinzugefügt werden. Darüber hinaus soll die Funktion eine Liste der Zielfunktionswerte des Generators und des Discriminators, die während des Trainings auftreten, zurückgeben.\n",
        "\n",
        "2. (2 Punkte) Trainieren Sie ein GAN auf dem FashionMNIST-Datensatz für 10 Epochen und erstellen Sie einen Plot der Zielfunktion des Generators und des Discriminators. Zeigen Sie 25 Bilder des Trainingsdatensatzes sowie den Verlauf der 25 Stichproben aus der gelernten Verteilung, die am Ende jeder Epoche erzeugt wurden, mit Hilfe der Funktion `show_image_grid` an.\n",
        "\n",
        "Hinweis: Da das Training eines GANs instabil sein kann, müssen Sie möglicherweise das Training mehrfach wiederholen oder die Hyperparameter anpassen, bis das Netzwerk konvergiert."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIrVjRpCtWhd"
      },
      "outputs": [],
      "source": [
        "# Bildet einen Tensor [50, 1, 1] auf ein Bild [1,28,28] ab\n",
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            # Block 1\n",
        "            nn.ConvTranspose2d(50, 64, 4, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            # Block 2\n",
        "            nn.ConvTranspose2d(64, 64, 4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            # Block 3\n",
        "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            # Output\n",
        "            nn.ConvTranspose2d(32, 1, 4, stride=2, padding=3, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(z)\n",
        "\n",
        "# Ein Bild auf ein Bild [1,28,28] auf einen Tensor [1,1,1] ab\n",
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            # Block 1\n",
        "            nn.Conv2d(1, 32, 4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(negative_slope=0.2),\n",
        "            # Block 2\n",
        "            nn.Conv2d(32, 64, 4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(negative_slope=0.2),\n",
        "            # Block 3\n",
        "            nn.Conv2d(64, 64, 4, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(negative_slope=0.2),\n",
        "            # Output\n",
        "            nn.Conv2d(64, 1, 4, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "def train_gan(num_epochs, dataloader, netD, optimizerD, netG, optimizerG):\n",
        "    G_losses, D_losses, img_list= [], [], []\n",
        "\n",
        "    # Beginn Ihrer Lösung\n",
        "    # Ende Ihrer Lösung\n",
        "    return G_losses, D_losses, img_list\n",
        "\n",
        "netD = Discriminator()\n",
        "netG = Generator()\n",
        "\n",
        "# Setup Adam optimizers for both G and D\n",
        "optimizerD = torch.optim.Adam(netD.parameters(), lr=0.0005, betas=(0.5, 0.999))\n",
        "optimizerG = torch.optim.Adam(netG.parameters(), lr=0.0003, betas=(0.5, 0.999))\n",
        "\n",
        "traindata = torchvision.datasets.FashionMNIST(\"./data\", train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
        "trainloader = torch.utils.data.DataLoader(traindata, batch_size=128, shuffle=True)\n",
        "G_losses, D_losses, img_list = train_gan(10, trainloader, netD, optimizerD, netG, optimizerG)\n",
        "\n",
        "# Visualisierung der Zielfunktionskurve und Bild\n",
        "# Begin Ihrer Lösung\n",
        "# Ende Ihrer Lösung\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dlvc",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "81f57b27ca37b55c596f080121424dcf7c0495475ff1affa9066a211553d9495"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}